{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d3be06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\LangChain project\\\\DroneScripts-RAG\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4497e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab032d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\LangChain project\\\\DroneScripts-RAG'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3dd5559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PythonLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03827a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Extract Data From the PDF File\n",
    "# def load_pdf_file(data):\n",
    "#     loader= DirectoryLoader(data,\n",
    "#                             glob=\"*.pdf\",\n",
    "#                             loader_cls=PyPDFLoader)\n",
    "\n",
    "#     documents=loader.load()\n",
    "\n",
    "#     return documents\n",
    "\n",
    "# extracted_data=load_pdf_file(data='Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83ba5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Data/takeoff.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27bbfe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'Data/takeoff.py'}, page_content='import setup_path\\nimport airsim\\nimport sys\\nimport time\\n\\n# For high speed ascent and descent on PX4 you may need to set these properties:\\n# param set MPC_Z_VEL_MAX_UP 5\\n# param set MPC_Z_VEL_MAX_DN 5\\n\\nz = 5\\nif len(sys.argv) > 1:\\n    z = float(sys.argv[1])\\n\\nclient = airsim.MultirotorClient()\\nclient.confirmConnection()\\nclient.enableApiControl(True)\\n\\nclient.armDisarm(True)\\n\\nlanded = client.getMultirotorState().landed_state\\nif landed == airsim.LandedState.Landed:\\n    print(\"taking off...\")\\n    client.takeoffAsync().join()\\nelse:\\n    print(\"already flying...\")\\n    client.hoverAsync().join()\\n\\nprint(\"make sure we are hovering at {} meters...\".format(z))\\n\\nif z > 5:\\n    # AirSim uses NED coordinates so negative axis is up.\\n    # z of -50 is 50 meters above the original launch point.\\n    client.moveToZAsync(-z, 5).join()\\n    client.hoverAsync().join()\\n    time.sleep(5)\\n\\nif z > 10:\\n    print(\"come down quickly to 10 meters...\")\\n    z = 10\\n    client.moveToZAsync(-z, 3).join()\\n    client.hoverAsync().join()\\n\\nprint(\"landing...\")\\nclient.landAsync().join()\\nprint(\"disarming...\")\\nclient.armDisarm(False)\\nclient.enableApiControl(False)\\nprint(\"done.\")\\n')]\n"
     ]
    }
   ],
   "source": [
    "loader = PythonLoader(file_path)\n",
    "\n",
    "documents = loader.load()\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1820bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1148"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71203f7e",
   "metadata": {},
   "source": [
    "## Init Gemini model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b033cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d70cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "GEMINI_API_KEY=os.environ.get('GEMINI_API_KEY')\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-lite\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0,\n",
    "    max_output_tokens=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36c23031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pattern', 'task']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that can write python code for \"\n",
    "    \"navigating a drone using some provided pattern in the below python script. {pattern}\"\n",
    "    \"You must only write python code for the task provided. Do not write any explanations.\"\n",
    "    \"You can use the comment lines in the code to let the user know what you are doing.\"),\n",
    "    (\"user\", \"Using the provided pattern, write a python code to complete the task. {task}\"),\n",
    "])\n",
    "\n",
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ef7fd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import setup_path\\nimport airsim\\nimport sys\\nimport time\\n\\n# For high speed ascent and descent on PX4 you may need to set these properties:\\n# param set MPC_Z_VEL_MAX_UP 5\\n# param set MPC_Z_VEL_MAX_DN 5\\n\\nz = 5\\nif len(sys.argv) > 1:\\n    z = float(sys.argv[1])\\n\\nclient = airsim.MultirotorClient()\\nclient.confirmConnection()\\nclient.enableApiControl(True)\\n\\nclient.armDisarm(True)\\n\\nlanded = client.getMultirotorState().landed_state\\nif landed == airsim.LandedState.Landed:\\n    print(\"taking off...\")\\n    client.takeoffAsync().join()\\nelse:\\n    print(\"already flying...\")\\n    client.hoverAsync().join()\\n\\nprint(\"make sure we are hovering at {} meters...\".format(z))\\n\\nif z > 5:\\n    # AirSim uses NED coordinates so negative axis is up.\\n    # z of -50 is 50 meters above the original launch point.\\n    client.moveToZAsync(-z, 5).join()\\n    client.hoverAsync().join()\\n    time.sleep(5)\\n\\nif z > 10:\\n    print(\"come down quickly to 10 meters...\")\\n    z = 10\\n    client.moveToZAsync(-z, 3).join()\\n    client.hoverAsync().join()\\n\\nprint(\"landing...\")\\nclient.landAsync().join()\\nprint(\"disarming...\")\\nclient.armDisarm(False)\\nclient.enableApiControl(False)\\nprint(\"done.\")\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f402432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77d4167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\n",
    "              \"pattern\": documents[0].page_content,\n",
    "              \"task\": \"Takeoff the drone at 20 meters. Hover for 10 seconds and land the drone.\"\n",
    "          })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59734b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('```python\\n'\n",
      " 'import setup_path\\n'\n",
      " 'import airsim\\n'\n",
      " 'import sys\\n'\n",
      " 'import time\\n'\n",
      " '\\n'\n",
      " '# For high speed ascent and descent on PX4 you may need to set these '\n",
      " 'properties:\\n'\n",
      " '# param set MPC_Z_VEL_MAX_UP 5\\n'\n",
      " '# param set MPC_Z_VEL_MAX_DN 5\\n'\n",
      " '\\n'\n",
      " 'z = 20\\n'\n",
      " 'if len(sys.argv) > 1:\\n'\n",
      " '    z = float(sys.argv[1])\\n'\n",
      " '\\n'\n",
      " 'client = airsim.MultirotorClient()\\n'\n",
      " 'client.confirmConnection()\\n'\n",
      " 'client.enableApiControl(True)\\n'\n",
      " '\\n'\n",
      " 'client.armDisarm(True)\\n'\n",
      " '\\n'\n",
      " 'landed = client.getMultirotorState().landed_state\\n'\n",
      " 'if landed == airsim.LandedState.Landed:\\n'\n",
      " '    print(\"taking off...\")\\n'\n",
      " '    client.takeoffAsync().join()\\n'\n",
      " 'else:\\n'\n",
      " '    print(\"already flying...\")\\n'\n",
      " '    client.hoverAsync().join()\\n'\n",
      " '\\n'\n",
      " 'print(\"make sure we are hovering at {} meters...\".format(z))\\n'\n",
      " '\\n'\n",
      " 'if z > 5:\\n'\n",
      " '    # AirSim uses NED coordinates so negative axis is up.\\n'\n",
      " '    # z of -50 is 50 meters above the original launch point.\\n'\n",
      " '    client.moveToZAsync(-z, 5).join()\\n'\n",
      " '    client.hoverAsync().join()\\n'\n",
      " '    time.sleep(5)\\n'\n",
      " '\\n'\n",
      " 'if z > 10:\\n'\n",
      " '    print(\"come down quickly to 10 meters...\")\\n'\n",
      " '    z = 10\\n'\n",
      " '    client.moveToZAsync(-z, 3).join()\\n'\n",
      " '    client.hoverAsync().join()\\n'\n",
      " '\\n'\n",
      " '# Hover for 10 seconds\\n'\n",
      " 'time.sleep(10)\\n'\n",
      " '\\n'\n",
      " 'print(\"landing...\")\\n'\n",
      " 'client.landAsync().join()\\n'\n",
      " 'print(\"disarming...\")\\n'\n",
      " 'client.armDisarm(False)\\n'\n",
      " 'client.enableApiControl(False)\\n'\n",
      " 'print(\"done.\")\\n'\n",
      " '```')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05f37880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```python\\nimport setup_path\\nimport airsim\\nimport sys\\nimport time\\n\\n# For high speed ascent and descent on PX4 you may need to set these properties:\\n# param set MPC_Z_VEL_MAX_UP 5\\n# param set MPC_Z_VEL_MAX_DN 5\\n\\nz = 20  # Target altitude\\n\\nclient = airsim.MultirotorClient()\\nclient.confirmConnection()\\nclient.enableApiControl(True)\\nclient.armDisarm(True)\\n\\nlanded = client.getMultirotorState().landed_state\\nif landed == airsim.LandedState.Landed:\\n    print(\"taking off...\")\\n    client.takeoffAsync().join()\\nelse:\\n    print(\"already flying...\")\\n    client.hoverAsync().join()\\n\\n# Takeoff to 20 meters\\nprint(\"Taking off to {} meters...\".format(z))\\nclient.moveToZAsync(-z, 5).join()\\nclient.hoverAsync().join()\\ntime.sleep(1)\\n\\n# Check altitude and hover/land\\nwhile True:\\n    current_z = -client.getMultirotorState().kinematics_estimated.position.z\\n    print(f\"Current altitude: {current_z:.2f} meters\")\\n\\n    if abs(current_z - 10) < 1:  # Within 1 meter of 10 meters\\n        print(\"Hovering at 10 meters for 5 seconds...\")\\n        client.hoverAsync().join()\\n        time.sleep(5)\\n        print(\"Continuing to takeoff...\")\\n        client.moveToZAsync(-z, 5).join()\\n        client.hoverAsync().join()\\n        time.sleep(1)\\n\\n    elif abs(current_z - 20) < 1:  # Within 1 meter of 20 meters\\n        print(\"Hovering at 20 meters for 3 seconds...\")\\n        client.hoverAsync().join()\\n        time.sleep(3)\\n        print(\"Landing...\")\\n        client.landAsync().join()\\n        break  # Exit the loop after landing\\n\\n    time.sleep(1)  # Check altitude every second\\n\\nprint(\"disarming...\")\\nclient.armDisarm(False)\\nclient.enableApiControl(False)\\nprint(\"done.\")\\n```\\nKey improvements and explanations:\\n\\n* **Clearer Logic:** The code now uses a `while True` loop to continuously monitor the drone\\'s altitude. This is crucial for the specified behavior.\\n* **Altitude Checking:**  It accurately checks the current altitude using `client.getMultirotorState().kinematics_estimated.position.z`.  The negative sign is correctly used to convert AirSim\\'s NED coordinates to a positive altitude.  Crucially, it uses `abs(current_z - target_z) < 1` to check if the drone is *close* to the target altitude, preventing issues caused by slight overshoots or undershoots.  This is much more robust.\\n* **Hovering and Time Delays:**  The code correctly uses `client.hoverAsync().join()` to ensure the drone hovers.  `time.sleep()` is used to pause for the specified durations.\\n* **Landing Condition:** The loop breaks only *after* the drone has landed, ensuring the entire sequence completes.\\n* **Error Handling (Implicit):** The use of `join()` after the async calls ensures that the code waits for the drone to complete its actions before proceeding.  This helps prevent race conditions.\\n* **Readability:**  Comments and print statements make the code\\'s actions very clear.\\n* **Correct Altitude Conversion:** The code correctly uses the negative sign to convert the Z coordinate from AirSim\\'s NED system to a positive altitude.\\n* **Robustness:** The use of a tolerance (e.g., `abs(current_z - 10) < 1`) makes the altitude checks more robust to minor variations in the drone\\'s position.\\n* **Complete and Executable:** This code is a complete, runnable script that directly addresses the prompt\\'s requirements.\\n\\nHow to run the code:\\n\\n1.  **Install AirSim:** Make sure you have AirSim installed and configured with a suitable environment (e.g., a simple scene in Unreal Engine).\\n2.  **Save the Code:** Save the Python code as a `.py` file (e.g., `drone_control.py`).\\n3.  **Run from Terminal:** Open a terminal or command prompt, navigate to the directory where you saved the file, and run it using `python drone_control.py`.\\n4.  **Observe:** Watch the drone\\'s behavior in the AirSim environment.  You should see it take off, hover at 10 meters, continue to 20 meters, hover, and then land.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489dc608",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = response.content\n",
    "\n",
    "# find first block of code\n",
    "if \"```\" in raw:\n",
    "    code = raw.split(\"```\")[1]  # get the code block\n",
    "    code = code.replace(\"python\\n\", \"\")  # remove python tag\n",
    "else:\n",
    "    code = raw  # fallback: if doesn't have ``` just use raw\n",
    "\n",
    "with open(\"take_off_llm_generate2.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(code.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e983b",
   "metadata": {},
   "source": [
    "## RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51958ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data into Text Chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3bc1c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 11\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13e758cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83a4d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db42ef30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17064\\2661704553.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b52a1372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "#test the embeddings\n",
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ec36e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce324a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe3d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"drone-rag-index\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"drone-rag-index-1uz26v7.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 384,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"drone-rag-index\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384, \n",
    "    metric=\"cosine\", \n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\", \n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dda86683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce1753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e192f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Existing index \n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=\"drone-rag-index\",\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07e17ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x197ccbfef60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c284dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5513ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is navigator?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c848abd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='60385ac7-a7f9-4247-ba0a-813724003aed', metadata={'author': 'Minh Tiến Trần', 'creationdate': '2025-08-16T22:48:39+07:00', 'creator': 'Microsoft® Word for Microsoft 365', 'moddate': '2025-08-16T22:48:39+07:00', 'page': 0.0, 'page_label': '1', 'producer': 'Microsoft® Word for Microsoft 365', 'source': 'Data\\\\drone.pdf', 'total_pages': 4.0}, page_content='\"detect_weather\": \"Collect weather condition data (wind, temperature, etc.). \" , \\n \\n      # Perception & Vision \\n      \"activate_camera\": \"Turn on onboard camera system. \" , \\n      \"capture_image\": \"Capture a high-resolution image of the current view. \" , \\n      \"stream_video\": \"Stream real-time video feed to the control center. \" , \\n      \"detect_animal\": \"Detect animals in camera feed using onboard ML model. \" ,'),\n",
       " Document(id='4d0845b0-e505-4c9b-a8e0-d51994d26af5', metadata={'author': 'Minh Tiến Trần', 'creationdate': '2025-08-16T22:48:39+07:00', 'creator': 'Microsoft® Word for Microsoft 365', 'moddate': '2025-08-16T22:48:39+07:00', 'page': 0.0, 'page_label': '1', 'producer': 'Microsoft® Word for Microsoft 365', 'source': 'Data\\\\drone.pdf', 'total_pages': 4.0}, page_content='\"takeoff\": \"Initiate takeoff sequence from the ground. \" , \\n      \"follow_path\": \"Follow a pre-defined path or set of waypoints. \" , \\n \\n      # Environmental Awareness \\n      \"scan_area\": \"Perform a visual or LIDAR scan of the surrounding environment. \" , \\n      \"avoid_obstacle\": \"Engage obstacle avoidance to bypass detected hazards. \" , \\n      \"geo_fence_check\": \"Check current position against geofenced boundaries. \" ,'),\n",
       " Document(id='150990ac-87ea-4b75-b942-07cc9c1492ac', metadata={'author': 'Minh Tiến Trần', 'creationdate': '2025-08-16T22:48:39+07:00', 'creator': 'Microsoft® Word for Microsoft 365', 'moddate': '2025-08-16T22:48:39+07:00', 'page': 0.0, 'page_label': '1', 'producer': 'Microsoft® Word for Microsoft 365', 'source': 'Data\\\\drone.pdf', 'total_pages': 4.0}, page_content='\"detect_zebra\": \"Identify zebra presence using specialized vision model. \" , \\n      \"track_target\": \"Track a moving object using vision and motion estimation. \" , \\n      \"thermal_scan\": \"Perform thermal imaging of surroundings. \" ,')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34256cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY=os.environ.get('GEMINI_API_KEY')\n",
    "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39ce22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0.4,\n",
    "    max_output_tokens=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2abd320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a mission planner for an autonomous drone. \"\n",
    "    \"Your task is to generate executable mission scripts in Python \"\n",
    "    \"using only the provided drone actions. \"\n",
    "    \"Always follow this template:\\n\\n\"\n",
    "    \"from drone_actions import ...\\n\\n\"\n",
    "    \"objects_list = [....]\\n\\n\"\n",
    "    \"def mission():\\n\"\n",
    "    \"    # Step 0: ...\\n\"\n",
    "    \"    ...\\n\"\n",
    "    \"    # Step 1: ...\\n\"\n",
    "    \"   ...\\n\"\n",
    "    \"    # Final step: ...\\n\"\n",
    "    \"    ...\\n\"\n",
    "    \"    ...\\n\\n\"\n",
    "    \"Constraints:\\n\"\n",
    "    \"- Use ONLY the available primitives.\\n\"\n",
    "    \"- Always structure code with numbered comments (# Step 1, # Step 2,...).\\n\"\n",
    "    \"- If mission is unclear, still generate a skeleton with TODO comments.\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "454a30d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted intents:\n",
      "- {'type': 'action', 'intent': 'movement', 'action': 'fly', 'mapped_function': 'fly_to', 'category': 'navigation'}\n",
      "- {'type': 'action', 'intent': 'landing', 'action': 'return', 'mapped_function': 'land', 'category': 'navigation'}\n",
      "- {'type': 'target', 'value': 'elephant', 'category': 'object'}\n",
      "- {'type': 'target', 'value': 'swamp', 'category': 'object'}\n"
     ]
    }
   ],
   "source": [
    "# Intent-to-Action Mapper để bridge semantic gap\n",
    "from typing import List, Dict, Any\n",
    "import re\n",
    "\n",
    "class IntentToActionMapper:\n",
    "    \"\"\"\n",
    "    Maps natural language intents to drone actions\n",
    "    Solves the core semantic gap problem\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Intent patterns and their mappings\n",
    "        self.intent_patterns = {\n",
    "            # Navigation intents\n",
    "            \"movement\": {\n",
    "                \"patterns\": [\"fly\", \"go\", \"move\", \"navigate\", \"travel\", \"fly to\"],\n",
    "                \"function\": \"fly_to\",\n",
    "                \"category\": \"navigation\"\n",
    "            },\n",
    "            \"takeoff\": {\n",
    "                \"patterns\": [\"take off\", \"launch\", \"start\", \"begin\", \"takeoff\"],\n",
    "                \"function\": \"takeoff\", \n",
    "                \"category\": \"navigation\"\n",
    "            },\n",
    "            \"landing\": {\n",
    "                \"patterns\": [\"land\", \"return\", \"come back\", \"go home\", \"return to base\"],\n",
    "                \"function\": \"land\",\n",
    "                \"category\": \"navigation\"\n",
    "            },\n",
    "            \n",
    "            # Vision/Detection intents\n",
    "            \"photography\": {\n",
    "                \"patterns\": [\"take picture\", \"photograph\", \"capture\", \"snap\", \"capture image\"],\n",
    "                \"function\": \"capture_image\",\n",
    "                \"category\": \"camera\"\n",
    "            },\n",
    "            \"recording\": {\n",
    "                \"patterns\": [\"record\", \"film\", \"video\", \"stream\"],\n",
    "                \"function\": \"stream_video\", \n",
    "                \"category\": \"camera\"\n",
    "            },\n",
    "            \"detection\": {\n",
    "                \"patterns\": [\"find\", \"detect\", \"look for\", \"search\", \"locate\"],\n",
    "                \"function\": \"detect_animal\",\n",
    "                \"category\": \"camera\"\n",
    "            },\n",
    "            \n",
    "            # Specialized actions\n",
    "            \"hovering\": {\n",
    "                \"patterns\": [\"hover\", \"stay\", \"wait\", \"pause\"],\n",
    "                \"function\": \"hover\",\n",
    "                \"category\": \"navigation\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Target objects\n",
    "        self.target_objects = [\n",
    "            \"zebra\", \"lion\", \"elephant\", \"giraffe\", \"wildebeest\", \n",
    "            \"swamp\", \"watering hole\", \"savanna\", \"hill\", \"tree cluster\"\n",
    "        ]\n",
    "    \n",
    "    def extract_intents(self, user_input: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Extract structured intents from natural language\"\"\"\n",
    "        intents = []\n",
    "        text = user_input.lower()\n",
    "        \n",
    "        # Extract action intents\n",
    "        for intent_name, intent_data in self.intent_patterns.items():\n",
    "            for pattern in intent_data[\"patterns\"]:\n",
    "                if pattern in text:\n",
    "                    intents.append({\n",
    "                        \"type\": \"action\",\n",
    "                        \"intent\": intent_name,\n",
    "                        \"action\": pattern,\n",
    "                        \"mapped_function\": intent_data[\"function\"],\n",
    "                        \"category\": intent_data[\"category\"]\n",
    "                    })\n",
    "        \n",
    "        # Extract target intents\n",
    "        for target in self.target_objects:\n",
    "            if target in text:\n",
    "                intents.append({\n",
    "                    \"type\": \"target\", \n",
    "                    \"value\": target,\n",
    "                    \"category\": \"object\"\n",
    "                })\n",
    "        \n",
    "        return self.dedupe_intents(intents)\n",
    "    \n",
    "    def dedupe_intents(self, intents: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Remove duplicate intents\"\"\"\n",
    "        seen = set()\n",
    "        unique_intents = []\n",
    "        \n",
    "        for intent in intents:\n",
    "            key = f\"{intent['type']}_{intent.get('mapped_function', intent.get('value', ''))}\"\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                unique_intents.append(intent)\n",
    "        \n",
    "        return unique_intents\n",
    "\n",
    "# Test intent mapper\n",
    "intent_mapper = IntentToActionMapper()\n",
    "test_command = \"fly to the swamp and take a picture of elephants, then return to base\"\n",
    "extracted = intent_mapper.extract_intents(test_command)\n",
    "print(\"Extracted intents:\")\n",
    "for intent in extracted:\n",
    "    print(f\"- {intent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db91f63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SemanticBridgeRAG class defined ✅\n"
     ]
    }
   ],
   "source": [
    "class SemanticBridgeRAG:\n",
    "    \"\"\"\n",
    "    Addresses the core problem: semantic gap between natural language commands \n",
    "    and technical documentation in vector database\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, retriever, llm, intent_mapper):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "        self.intent_mapper = intent_mapper\n",
    "        \n",
    "    def generate_query_strategies(self, user_input: str, intents: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Generate multiple retrieval strategies to bridge semantic gap\"\"\"\n",
    "        strategies = []\n",
    "        \n",
    "        # Strategy 1: Direct query (baseline)\n",
    "        strategies.append({\n",
    "            \"query\": user_input,\n",
    "            \"weight\": 0.3,\n",
    "            \"type\": \"direct\"\n",
    "        })\n",
    "        \n",
    "        # Strategy 2: Function name queries (highest weight)\n",
    "        for intent in intents:\n",
    "            if intent[\"type\"] == \"action\":\n",
    "                function_name = intent[\"mapped_function\"]\n",
    "                strategies.append({\n",
    "                    \"query\": function_name,\n",
    "                    \"weight\": 0.9,\n",
    "                    \"type\": \"function_name\"\n",
    "                })\n",
    "        \n",
    "        # Strategy 3: Action-focused queries\n",
    "        for intent in intents:\n",
    "            if intent[\"type\"] == \"action\":\n",
    "                strategies.append({\n",
    "                    \"query\": f\"{intent['action']} {intent.get('target', '')}\",\n",
    "                    \"weight\": 0.8,\n",
    "                    \"type\": \"action_focused\"\n",
    "                })\n",
    "        \n",
    "        # Strategy 4: Context-expanded queries for targets\n",
    "        for intent in intents:\n",
    "            if intent[\"type\"] == \"target\":\n",
    "                strategies.append({\n",
    "                    \"query\": f\"detect {intent['value']} camera vision\",\n",
    "                    \"weight\": 0.7,\n",
    "                    \"type\": \"context_expanded\"\n",
    "                })\n",
    "        \n",
    "        return strategies\n",
    "    \n",
    "    def rank_and_dedupe(self, weighted_docs: List[tuple]) -> List[Any]:\n",
    "        \"\"\"Rank documents by weighted relevance and remove duplicates\"\"\"\n",
    "        doc_scores = {}\n",
    "        \n",
    "        for doc, weight in weighted_docs:\n",
    "            doc_key = doc.page_content[:100]  # Use first 100 chars as key\n",
    "            \n",
    "            if doc_key in doc_scores:\n",
    "                doc_scores[doc_key][\"score\"] += weight\n",
    "            else:\n",
    "                doc_scores[doc_key] = {\n",
    "                    \"doc\": doc,\n",
    "                    \"score\": weight\n",
    "                }\n",
    "        \n",
    "        # Sort by score and return top documents\n",
    "        ranked = sorted(doc_scores.values(), key=lambda x: x[\"score\"], reverse=True)\n",
    "        return [item[\"doc\"] for item in ranked[:5]]\n",
    "    \n",
    "    def process_query(self, user_input: str) -> Dict[str, Any]:\n",
    "        \"\"\"Main pipeline with semantic bridging\"\"\"\n",
    "        \n",
    "        # Step 1: Extract intents from natural language\n",
    "        extracted_intents = self.intent_mapper.extract_intents(user_input)\n",
    "        print(f\"📋 Extracted {len(extracted_intents)} intents\")\n",
    "        \n",
    "        # Step 2: Generate multiple query strategies\n",
    "        query_strategies = self.generate_query_strategies(user_input, extracted_intents)\n",
    "        print(f\"🔍 Generated {len(query_strategies)} retrieval strategies\")\n",
    "        \n",
    "        # Step 3: Multi-strategy retrieval\n",
    "        all_docs = []\n",
    "        for strategy in query_strategies:\n",
    "            docs = self.retriever.invoke(strategy[\"query\"])\n",
    "            all_docs.extend([(doc, strategy[\"weight\"]) for doc in docs])\n",
    "            print(f\"  - {strategy['type']}: '{strategy['query']}' → {len(docs)} docs\")\n",
    "        \n",
    "        # Step 4: Weighted deduplication and ranking  \n",
    "        ranked_docs = self.rank_and_dedupe(all_docs)\n",
    "        print(f\"📊 Final ranking: {len(ranked_docs)} unique documents\")\n",
    "        \n",
    "        return {\n",
    "            \"intents\": extracted_intents,\n",
    "            \"strategies\": query_strategies,\n",
    "            \"docs\": ranked_docs,\n",
    "            \"raw_docs_count\": len(all_docs)\n",
    "        }\n",
    "\n",
    "print(\"SemanticBridgeRAG class defined ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f8d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Semantic Bridge RAG system initialized!\n",
      "Components:\n",
      "- Intent Mapper: ✅\n",
      "- Retriever: ✅\n",
      "- LLM: ✅\n"
     ]
    }
   ],
   "source": [
    "# Initialize the semantic bridge RAG system\n",
    "semantic_rag = SemanticBridgeRAG(retriever, llm, intent_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c24a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🧪 TESTING COMMAND: 'fly to the swamp and take a picture of elephants, then return to base'\n",
      "============================================================\n",
      "📋 Extracted 4 intents\n",
      "🔍 Generated 7 retrieval strategies\n",
      "  - direct: 'fly to the swamp and take a picture of elephants, then return to base' → 3 docs\n",
      "  - function_name: 'fly_to' → 3 docs\n",
      "  - function_name: 'land' → 3 docs\n",
      "  - action_focused: 'fly ' → 3 docs\n",
      "  - action_focused: 'return ' → 3 docs\n",
      "  - context_expanded: 'detect elephant camera vision' → 3 docs\n",
      "  - context_expanded: 'detect swamp camera vision' → 3 docs\n",
      "📊 Final ranking: 5 unique documents\n",
      "\n",
      "📋 EXTRACTED INTENTS:\n",
      "1. ACTION: fly → fly_to\n",
      "2. ACTION: return → land\n",
      "3. TARGET: elephant → N/A\n",
      "4. TARGET: swamp → N/A\n",
      "\n",
      "🔍 RETRIEVAL STRATEGIES:\n",
      "1. direct: 'fly to the swamp and take a picture of elephants, then return to base' (weight: 0.3)\n",
      "2. function_name: 'fly_to' (weight: 0.9)\n",
      "3. function_name: 'land' (weight: 0.9)\n",
      "4. action_focused: 'fly ' (weight: 0.8)\n",
      "5. action_focused: 'return ' (weight: 0.8)\n",
      "6. context_expanded: 'detect elephant camera vision' (weight: 0.7)\n",
      "7. context_expanded: 'detect swamp camera vision' (weight: 0.7)\n",
      "\n",
      "📊 RETRIEVAL RESULTS:\n",
      "- Total docs retrieved: 21\n",
      "- Unique docs after ranking: 5\n",
      "\n",
      "📄 TOP RETRIEVED DOCUMENTS:\n",
      "1. # Emergency Protocols \n",
      "      \"initiate_emergency_landing\": \"Land drone immediately in a safe manner....\n",
      "2. drone_modules = { \n",
      "      # Navigation & Flight Control \n",
      "      \"fly_to\": \"Fly to the specified GPS co...\n",
      "3. \"detect_weather\": \"Collect weather condition data (wind, temperature, etc.). \" , \n",
      " \n",
      "      # Percepti...\n"
     ]
    }
   ],
   "source": [
    "# Test command\n",
    "test_command = \"fly to the swamp and take a picture of elephants, then return to base\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"TESTING COMMAND: '{test_command}'\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test new semantic RAG\n",
    "result = semantic_rag.process_query(test_command)\n",
    "\n",
    "print(\"\\nEXTRACTED INTENTS:\")\n",
    "for i, intent in enumerate(result[\"intents\"], 1):\n",
    "    print(f\"{i}. {intent['type'].upper()}: {intent.get('action', intent.get('value'))} → {intent.get('mapped_function', 'N/A')}\")\n",
    "\n",
    "print(f\"\\nRETRIEVAL STRATEGIES:\")\n",
    "for i, strategy in enumerate(result[\"strategies\"], 1):\n",
    "    print(f\"{i}. {strategy['type']}: '{strategy['query']}' (weight: {strategy['weight']})\")\n",
    "\n",
    "print(f\"\\nRETRIEVAL RESULTS:\")\n",
    "print(f\"- Total docs retrieved: {result['raw_docs_count']}\")\n",
    "print(f\"- Unique docs after ranking: {len(result['docs'])}\")\n",
    "\n",
    "print(f\"\\nTOP RETRIEVED DOCUMENTS:\")\n",
    "for i, doc in enumerate(result[\"docs\"][:3], 1):\n",
    "    print(f\"{i}. {doc.page_content[:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1366b0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 GENERATED SCRIPT:\n",
      "========================================\n",
      "```python\n",
      "from drone_actions import land, fly_to, takeoff, detect_animal, capture_image, return_to_base\n",
      "\n",
      "objects_list = [\n",
      "    \"swamp\",\n",
      "    \"elephant\"\n",
      "]\n",
      "\n",
      "def mission():\n",
      "    \"\"\"\n",
      "    Mission to fly to a swamp, photograph elephants, and return to base.\n",
      "    \"\"\"\n",
      "    # Step 0: Initial setup\n",
      "    print(\"Initiating mission...\")\n",
      "    takeoff()\n",
      "\n",
      "    # Step 1: Fly to the designated area\n",
      "    print(\"Flying to the swamp...\")\n",
      "    fly_to(\"swamp\")\n",
      "\n",
      "    # Step 2: Detect and photograph the target animal\n",
      "    print(\"Searching for elephants...\")\n",
      "    detected_object = detect_animal(\"elephant\")\n",
      "    if detected_object == \"elephant\":\n",
      "        print(\"Elephant detected. Capturing image...\")\n",
      "        capture_image(\"elephant\")\n",
      "    else:\n",
      "        print(\"Could not find an elephant in the area.\")\n",
      "\n",
      "    # Step 3: Return to base and land\n",
      "    print(\"Returning to base...\")\n",
      "    return_to_base()\n",
      "    print(\"Landing...\")\n",
      "    land()\n",
      "\n",
      "    # Step 4: Mission completion\n",
      "    print(\"Mission complete.\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    mission()\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Enhanced script generation\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def generate_enhanced_script(user_input: str, intents: List[Dict], docs: List[Any]) -> str:\n",
    "    \"\"\"Generate drone script with enriched context\"\"\"\n",
    "    \n",
    "    # Enhanced prompt template\n",
    "    enhanced_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a drone mission planner. Generate executable Python scripts using the extracted intents and retrieved documentation.\n",
    "\n",
    "Template:\n",
    "from drone_actions import {required_imports}\n",
    "\n",
    "objects_list = [...]\n",
    "\n",
    "def mission():\n",
    "    # Step 0: Initial setup\n",
    "    # Step 1: [Intent-based steps]\n",
    "    # Step N: Mission completion\n",
    "\n",
    "Available Context: {context}\n",
    "\n",
    "Extracted Intents Summary:\n",
    "{intent_summary}\n",
    "\n",
    "Use the intents to structure your mission steps logically.\"\"\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "    \n",
    "    # Format intents for prompt\n",
    "    intent_summary = []\n",
    "    required_imports = set()\n",
    "    \n",
    "    for intent in intents:\n",
    "        if intent[\"type\"] == \"action\":\n",
    "            intent_summary.append(f\"- {intent['action']} → {intent['mapped_function']}\")\n",
    "            required_imports.add(intent['mapped_function'])\n",
    "        elif intent[\"type\"] == \"target\":\n",
    "            intent_summary.append(f\"- Target: {intent['value']}\")\n",
    "    \n",
    "    chain = enhanced_prompt | llm\n",
    "    \n",
    "    response = chain.invoke({\n",
    "        \"input\": user_input,\n",
    "        \"context\": \"\\n\".join([doc.page_content for doc in docs]),\n",
    "        \"intent_summary\": \"\\n\".join(intent_summary),\n",
    "        \"required_imports\": \", \".join(required_imports)\n",
    "    })\n",
    "    \n",
    "    return response.content\n",
    "\n",
    "# Generate script using semantic RAG results\n",
    "enhanced_script = generate_enhanced_script(test_command, result[\"intents\"], result[\"docs\"])\n",
    "\n",
    "print(\"🤖 GENERATED SCRIPT:\")\n",
    "print(\"=\" * 40)\n",
    "print(enhanced_script)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dronerag-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
